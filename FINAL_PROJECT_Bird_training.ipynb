{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL PROJECT Bird training",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPZ+SS9eH+1NiFlzU1nyFCv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huune2k/BTVN_AI_8-8-2022/blob/AI_8-5-2022/FINAL_PROJECT_Bird_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRhkRyoO1eyL",
        "outputId": "f0ed59bd-7d00-47e3-d4db-37006c96af90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/gdrive/MyDrive/Colab/Bird1/Bird1-20220620T002605Z-001.zip\" -d \"/content/gdrive/MyDrive/Colab/Bird1\""
      ],
      "metadata": {
        "id": "kQijSvyq10zT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "\n",
        "direction = Path('/content/gdrive/MyDrive/Colab/Bird1/Bird1')"
      ],
      "metadata": {
        "id": "HnzT0BRB1xdW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset from file list \n",
        "filelist_ds = tf.data.Dataset.list_files(str(direction/'*/*'))\n",
        "\n",
        "ds_size = 11788\n",
        "train_size = int(ds_size*0.8)\n",
        "val_size = int(ds_size*0.2)\n",
        "\n",
        "filelist_ds = filelist_ds.shuffle(ds_size)\n",
        "train_file = filelist_ds.take(train_size) \n",
        "val_file = filelist_ds.take(val_size) \n",
        "\n",
        "for file in filelist_ds.take(3):\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCjo5seq27Jb",
        "outputId": "fcb5bccf-6a97-4a0f-e386-7e6f1f08fc70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'/content/gdrive/MyDrive/Colab/Bird1/Bird1/156.White_eyed_Vireo/White_Eyed_Vireo_0132_158908.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/content/gdrive/MyDrive/Colab/Bird1/Bird1/082.Ringed_Kingfisher/Ringed_Kingfisher_0057_72812.jpg', shape=(), dtype=string)\n",
            "tf.Tensor(b'/content/gdrive/MyDrive/Colab/Bird1/Bird1/088.Western_Meadowlark/Western_Meadowlark_0021_78841.jpg', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(file_path):\n",
        "  labels = []\n",
        "  parts = tf.strings.split(file_path,'/')\n",
        "  text = parts[-2]\n",
        "  text_split = tf.strings.split(text,'.')\n",
        "  number_label = int(text_split[0])\n",
        "  labels = [1 if x == number_label else 0 for x in range(1,201,1)]\n",
        "  return tf.convert_to_tensor(labels) \n"
      ],
      "metadata": {
        "id": "CszJejge3guM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_h = 224\n",
        "img_w = 224\n",
        "\n",
        "def preprocessing(file_path):\n",
        "  # read file\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "  # convert from uint8 to float32 and normalize values to [0, 1]\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize image\n",
        "  img = tf.image.resize(img, [img_w, img_h])\n",
        "\n",
        "  # get image label\n",
        "  label = get_label(file_path)\n",
        "\n",
        "  # return\n",
        "  return img, label "
      ],
      "metadata": {
        "id": "JyWaK7Sn29Ui"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Build train dataset\n",
        "train_ds = filelist_ds.shuffle(train_size)\n",
        "train_ds = train_ds.map(preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#train_ds = train_ds.map(lambda x:tf.function(preprocessing, [x], [tf.float32,tf.int32]))\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.prefetch(1)\n",
        "\n",
        "# Build val dataset\n",
        "val_ds = filelist_ds.shuffle(val_size)\n",
        "val_ds = val_ds.map(preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#val_ds = val_ds.map(lambda x:tf.function(preprocessing, [x], [tf.float32,tf.int32]))\n",
        "val_ds = val_ds.batch(batch_size)\n",
        "val_ds = val_ds.prefetch(1)\n",
        "''' \n",
        "for file in train_ds.take(3):\n",
        "  print(file)  '''\n",
        "\n",
        "print(train_ds)\n",
        "print(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAFcxAaB3Q9w",
        "outputId": "b6d55ebf-554d-4670-aad8-c44abfb61d3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 200), dtype=tf.int32, name=None))>\n",
            "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 200), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(224,224,3)))\n",
        "model.add(layers.Conv2D(32, 3, (2,2), padding= 'valid', activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(1,1), strides=2))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Conv2D(32, 3, (2,2), padding= 'valid', activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(1,1), strides=2))\n",
        "model.add(layers.Dropout(0.25))\n",
        "\n",
        "# model.add(layers.Conv2D(32, 3, (3,3), padding= 'valid', activation='relu'))\n",
        "# model.add(layers.MaxPooling2D(pool_size=(1,1), strides=2))\n",
        "# model.add(layers.Dropout(0.25))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.25))\n",
        "model.add(layers.Dense(1000, activation='relu'))\n",
        "model.add(layers.Dense(200, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "ExQ6Mx8d3Soo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "9UUJJozw3mJe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIc4Xu193okL",
        "outputId": "5b2e2c99-a50b-4bee-c585-dfc95ca9e6bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "737/737 [==============================] - 1846s 2s/step - loss: 5.1775 - accuracy: 0.0120 - val_loss: 4.8779 - val_accuracy: 0.0378\n",
            "Epoch 2/50\n",
            "737/737 [==============================] - 53s 73ms/step - loss: 4.7250 - accuracy: 0.0447 - val_loss: 4.3626 - val_accuracy: 0.0934\n",
            "Epoch 3/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 4.2797 - accuracy: 0.0843 - val_loss: 3.8031 - val_accuracy: 0.1906\n",
            "Epoch 4/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 3.7018 - accuracy: 0.1720 - val_loss: 2.8515 - val_accuracy: 0.4159\n",
            "Epoch 5/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 2.9739 - accuracy: 0.3092 - val_loss: 1.8981 - val_accuracy: 0.6216\n",
            "Epoch 6/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 2.1296 - accuracy: 0.4927 - val_loss: 1.0935 - val_accuracy: 0.7950\n",
            "Epoch 7/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 1.4414 - accuracy: 0.6445 - val_loss: 0.6243 - val_accuracy: 0.9044\n",
            "Epoch 8/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.9863 - accuracy: 0.7497 - val_loss: 0.3773 - val_accuracy: 0.9422\n",
            "Epoch 9/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.7089 - accuracy: 0.8235 - val_loss: 0.1793 - val_accuracy: 0.9721\n",
            "Epoch 10/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.5454 - accuracy: 0.8581 - val_loss: 0.1204 - val_accuracy: 0.9831\n",
            "Epoch 11/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.4432 - accuracy: 0.8875 - val_loss: 0.0823 - val_accuracy: 0.9874\n",
            "Epoch 12/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.3993 - accuracy: 0.9036 - val_loss: 0.0581 - val_accuracy: 0.9922\n",
            "Epoch 13/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.3199 - accuracy: 0.9180 - val_loss: 0.0414 - val_accuracy: 0.9947\n",
            "Epoch 14/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.2749 - accuracy: 0.9273 - val_loss: 0.0307 - val_accuracy: 0.9963\n",
            "Epoch 15/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.2731 - accuracy: 0.9314 - val_loss: 0.0202 - val_accuracy: 0.9981\n",
            "Epoch 16/50\n",
            "737/737 [==============================] - 55s 74ms/step - loss: 0.2426 - accuracy: 0.9405 - val_loss: 0.0274 - val_accuracy: 0.9969\n",
            "Epoch 17/50\n",
            "737/737 [==============================] - 55s 74ms/step - loss: 0.2413 - accuracy: 0.9404 - val_loss: 0.0173 - val_accuracy: 0.9978\n",
            "Epoch 18/50\n",
            "737/737 [==============================] - 54s 74ms/step - loss: 0.2071 - accuracy: 0.9466 - val_loss: 0.0166 - val_accuracy: 0.9980\n",
            "Epoch 19/50\n",
            "737/737 [==============================] - 54s 74ms/step - loss: 0.1918 - accuracy: 0.9487 - val_loss: 0.0140 - val_accuracy: 0.9983\n",
            "Epoch 20/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.1859 - accuracy: 0.9537 - val_loss: 0.0121 - val_accuracy: 0.9981\n",
            "Epoch 21/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.1785 - accuracy: 0.9571 - val_loss: 0.0111 - val_accuracy: 0.9982\n",
            "Epoch 22/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1829 - accuracy: 0.9533 - val_loss: 0.0078 - val_accuracy: 0.9992\n",
            "Epoch 23/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1786 - accuracy: 0.9567 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
            "Epoch 24/50\n",
            "737/737 [==============================] - 53s 73ms/step - loss: 0.1619 - accuracy: 0.9609 - val_loss: 0.0110 - val_accuracy: 0.9981\n",
            "Epoch 25/50\n",
            "737/737 [==============================] - 54s 74ms/step - loss: 0.1569 - accuracy: 0.9617 - val_loss: 0.0100 - val_accuracy: 0.9987\n",
            "Epoch 26/50\n",
            "737/737 [==============================] - 54s 74ms/step - loss: 0.1835 - accuracy: 0.9558 - val_loss: 0.0105 - val_accuracy: 0.9978\n",
            "Epoch 27/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1345 - accuracy: 0.9655 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
            "Epoch 28/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1551 - accuracy: 0.9625 - val_loss: 0.0090 - val_accuracy: 0.9989\n",
            "Epoch 29/50\n",
            "737/737 [==============================] - 53s 73ms/step - loss: 0.1344 - accuracy: 0.9672 - val_loss: 0.0077 - val_accuracy: 0.9989\n",
            "Epoch 30/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1444 - accuracy: 0.9634 - val_loss: 0.0200 - val_accuracy: 0.9958\n",
            "Epoch 31/50\n",
            "737/737 [==============================] - 53s 73ms/step - loss: 0.1428 - accuracy: 0.9667 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
            "Epoch 32/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.1214 - accuracy: 0.9713 - val_loss: 0.0031 - val_accuracy: 0.9997\n",
            "Epoch 33/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.1266 - accuracy: 0.9706 - val_loss: 0.0051 - val_accuracy: 0.9994\n",
            "Epoch 34/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1310 - accuracy: 0.9672 - val_loss: 0.0058 - val_accuracy: 0.9990\n",
            "Epoch 35/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1253 - accuracy: 0.9701 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
            "Epoch 36/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1338 - accuracy: 0.9684 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
            "Epoch 37/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.1397 - accuracy: 0.9693 - val_loss: 0.0026 - val_accuracy: 0.9994\n",
            "Epoch 38/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.1193 - accuracy: 0.9697 - val_loss: 0.0074 - val_accuracy: 0.9990\n",
            "Epoch 39/50\n",
            "737/737 [==============================] - 54s 73ms/step - loss: 0.1061 - accuracy: 0.9735 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
            "Epoch 40/50\n",
            "737/737 [==============================] - 53s 71ms/step - loss: 0.1195 - accuracy: 0.9728 - val_loss: 0.0037 - val_accuracy: 0.9997\n",
            "Epoch 41/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1207 - accuracy: 0.9713 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
            "Epoch 42/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1214 - accuracy: 0.9715 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
            "Epoch 43/50\n",
            "737/737 [==============================] - 52s 71ms/step - loss: 0.1105 - accuracy: 0.9755 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
            "Epoch 44/50\n",
            "737/737 [==============================] - 52s 71ms/step - loss: 0.1028 - accuracy: 0.9760 - val_loss: 0.0028 - val_accuracy: 0.9997\n",
            "Epoch 45/50\n",
            "737/737 [==============================] - 53s 71ms/step - loss: 0.1067 - accuracy: 0.9746 - val_loss: 0.0024 - val_accuracy: 0.9993\n",
            "Epoch 46/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.0902 - accuracy: 0.9780 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 47/50\n",
            "737/737 [==============================] - 52s 71ms/step - loss: 0.1162 - accuracy: 0.9726 - val_loss: 0.0064 - val_accuracy: 0.9996\n",
            "Epoch 48/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.1086 - accuracy: 0.9759 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
            "Epoch 49/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.0902 - accuracy: 0.9781 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 50/50\n",
            "737/737 [==============================] - 53s 72ms/step - loss: 0.0997 - accuracy: 0.9771 - val_loss: 0.0023 - val_accuracy: 0.9997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ef5145410>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "file_name = \"/content/gdrive/MyDrive/Colab/Bird1/birdtraining16batch50epoch.sav\"\n",
        "pickle.dump(model, open(file_name, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP4AMohG3rCW",
        "outputId": "fc3f6ee4-f962-47b7-c405-a38ff6c00ee6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://5f072046-de69-421f-8607-3a5867beed58/assets\n"
          ]
        }
      ]
    }
  ]
}